{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80fe60ba",
   "metadata": {},
   "source": [
    "# Coronary Heart Disease Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc648b",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbc34d",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we perform a machine learning analysis to predict coronary heart disease (CHD) risk using a dataset. We'll go through the following steps:\n",
    "\n",
    "- Importing the required packages\n",
    "- Importing and displaying an overview of the dataset\n",
    "- Preprocessing the data\n",
    "- Training and evaluating different machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed2f37",
   "metadata": {},
   "source": [
    "### 1. Importing the Required Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6ff0f",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary Python packages for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da582be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba519a43",
   "metadata": {},
   "source": [
    "### 2. Importing & Displaying an Overview of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36e628",
   "metadata": {},
   "source": [
    "Now, we'll load and take a quick look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4754739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>isSmoker</th>\n",
       "      <th>CigsPerDay</th>\n",
       "      <th>BloodPressureMeds</th>\n",
       "      <th>PrevStroke</th>\n",
       "      <th>PrevHypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>SysBloodPressure</th>\n",
       "      <th>DiaBloodPressure</th>\n",
       "      <th>BMI</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>RiskCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.30</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Age  isSmoker  CigsPerDay  BloodPressureMeds  PrevStroke  \\\n",
       "0    1   39         0         0.0                0.0           0   \n",
       "1    0   46         0         0.0                0.0           0   \n",
       "2    1   48         1        20.0                0.0           0   \n",
       "3    0   46         1        23.0                0.0           0   \n",
       "4    0   43         0         0.0                0.0           0   \n",
       "\n",
       "   PrevHypertension  Diabetes  Cholesterol  SysBloodPressure  \\\n",
       "0                 0         0        195.0             106.0   \n",
       "1                 0         0        250.0             121.0   \n",
       "2                 0         0        245.0             127.5   \n",
       "3                 0         0        285.0             130.0   \n",
       "4                 1         0        228.0             180.0   \n",
       "\n",
       "   DiaBloodPressure    BMI  HeartRate  Glucose  RiskCHD  \n",
       "0              70.0  26.97       80.0     77.0        0  \n",
       "1              81.0  28.73       95.0     76.0        0  \n",
       "2              80.0  25.34       75.0     70.0        0  \n",
       "3              84.0  23.10       85.0     85.0        0  \n",
       "4             110.0  30.30       77.0     99.0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Suivi.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c3e43",
   "metadata": {},
   "source": [
    "### 3. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc8811",
   "metadata": {},
   "source": [
    "We'll preprocess the data by selecting relevant features, splitting it into training and testing sets, and standardizing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95367831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['RiskCHD']\n",
    "X = df[['Sex', 'Age', 'isSmoker', 'CigsPerDay', 'BloodPressureMeds', 'PrevStroke', 'Diabetes', 'Cholesterol', 'SysBloodPressure', 'DiaBloodPressure', 'BMI', 'HeartRate', 'Glucose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e62193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets with random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4127b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312abcd",
   "metadata": {},
   "source": [
    "### 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba178f2",
   "metadata": {},
   "source": [
    "We will train and evaluate the following machine learning models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6823ff2",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa5d8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classifier:\n",
      "Accuracy: 0.6838487972508591\n",
      "Precision: 0.6701421800947868\n",
      "Recall: 0.7048853439680958\n",
      "F1 Score: 0.6870748299319728\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(random_state=4)\n",
    "lr_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"\\nLogistic Regression Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_lr))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcec0be",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44cfee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine Classifier:\n",
      "Accuracy: 0.7103583701521846\n",
      "Precision: 0.6949952785646837\n",
      "Recall: 0.7337986041874377\n",
      "F1 Score: 0.7138700290979632\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC(random_state=4)\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Support Vector Machine\n",
    "print(\"\\nSupport Vector Machine Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895d595",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4023499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.9597447226313206\n",
      "Precision: 0.9332079021636877\n",
      "Recall: 0.9890329012961117\n",
      "F1 Score: 0.9603097773475314\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=4)\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd335d0",
   "metadata": {},
   "source": [
    "#### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69999c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.8919980363279333\n",
      "Precision: 0.8265221017514596\n",
      "Recall: 0.9880358923230309\n",
      "F1 Score: 0.9000908265213443\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=4)\n",
    "dt_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c87b1",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06109a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classifier:\n",
      "Accuracy: 0.738831615120275\n",
      "Precision: 0.7162534435261708\n",
      "Recall: 0.7776669990029911\n",
      "F1 Score: 0.7456978967495221\n"
     ]
    }
   ],
   "source": [
    "gb_classifier = GradientBoostingClassifier(random_state=4)\n",
    "gb_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "print(\"\\nGradient Boosting Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_gb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7ae5a",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Model with Hyperparameter Tuning (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f0fb43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classifier + GridSearchCV:\n",
      "Accuracy: 0.9597447226313206\n",
      "Precision: 0.9332079021636877\n",
      "Recall: 0.9890329012961117\n",
      "F1 Score: 0.9603097773475314\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=4)\n",
    "gb_grid = GridSearchCV(gb_classifier, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "gb_grid.fit(X_train_scaled, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "y_pred_gb = best_gb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Gradient Boosting with GridSearchCV\n",
    "print(\"\\nGradient Boosting Classifier + GridSearchCV:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a0d0f",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eaf690",
   "metadata": {},
   "source": [
    "In this analysis, we explored various machine learning models to predict coronary heart disease (CHD) risk. The Random Forest Classifier achieved the highest F1 score, suggesting its effectiveness in this prediction task. Further hyperparameter tuning of the Gradient Boosting Classifier using GridSearchCV might yield even better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
